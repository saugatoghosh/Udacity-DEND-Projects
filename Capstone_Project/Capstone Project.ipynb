{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016 Immigration Sources And Destination Model\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The goal of this project is to use the Udacity provided I94 Immigration Dataset and the U.S. City Demographic Dataset to create a database. This database can be used to answer questions about where (countries) immigrants were coming from and where (cities in the U.S.) they were coming to over different periods of time. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "\n",
    "The objective of this project is to gather information about which countries immigrants are coming from, what are their modes of travel, types of visa and which cities in the U.S. they are coming to in order to analyze if demographics of cities imfluence immigration patterns. \n",
    "\n",
    "The datasets used are the I94 immigration dataset for April 2016 along with data dictionary and the city demographcs dataset provided by Udacity. \n",
    "\n",
    "The end solution is a number of dimension tables and a fact table arranged in a star schema as detailed below in the conceptual data model section. \n",
    "\n",
    "Spark was used to process the data. \n",
    "\n",
    "#### Describe and Gather Data \n",
    "The I94 immigration dataset comes from US National Tourism and Trade Office and is available [here](https://travel.trade.gov/research/reports/i94/historical/2016.html). \n",
    "For the purpose of the present analysis the following columns are relevant:-\n",
    "\n",
    "- i94cit - 3 digit code of the origin country\n",
    "- i94port - 3 character code of port of entry\n",
    "- arrdate - arrival date in the U.S.\n",
    "- i94mode - 1 digit code indicating mode of travel\n",
    "- i94bir - age of immigrant\n",
    "- i94visa - 1 digit code indicating reason for immigration\n",
    "- count\n",
    "\n",
    "The city demographics data comes from Opensoft and can be explored further [here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/information/). For the purpose of the present analysis the following columns are relevant:\n",
    "- City\n",
    "- State Code\n",
    "- Median Age\n",
    "- Male Population\n",
    "- Female Population\n",
    "- Total Population\n",
    "- Foreign-born\n",
    "- Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>DOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr  depdate  i94bir  i94visa  count   ...     visapost occup  \\\n",
       "0      1.0      HI  20573.0    61.0      2.0    1.0   ...          NaN   NaN   \n",
       "1      1.0      TX  20568.0    26.0      2.0    1.0   ...          MTR   NaN   \n",
       "2      1.0      FL  20571.0    76.0      2.0    1.0   ...          NaN   NaN   \n",
       "3      1.0      CA  20581.0    25.0      2.0    1.0   ...          DOH   NaN   \n",
       "4      3.0      NY  20553.0    19.0      2.0    1.0   ...          NaN   NaN   \n",
       "\n",
       "  entdepa entdepd entdepu  matflag biryear   dtaddto gender insnum  airline  \\\n",
       "0       G       O     NaN        M  1955.0  07202016      F    NaN       JL   \n",
       "1       G       R     NaN        M  1990.0  10222016      M    NaN      *GA   \n",
       "2       G       O     NaN        M  1940.0  07052016      M    NaN       LH   \n",
       "3       G       O     NaN        M  1991.0  10272016      M    NaN       QR   \n",
       "4       Z       K     NaN        M  1997.0  07042016      F    NaN      NaN   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  \n",
       "2  5.578047e+10  00464       WT  \n",
       "3  9.478970e+10  00739       B2  \n",
       "4  4.232257e+10   LAND       WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in sample immigration data\n",
    "df_imm_sample = pd.read_csv('immigration_data_sample.csv')\n",
    "df_imm_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in city demographics data set\n",
    "df_cities = pd.read_csv('us-cities-demographics.csv', sep = ';')\n",
    "print(df_cities.shape)\n",
    "df_cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the purpose of the present analysis we will only use the immigration data pertaining to April 2016, which contain over 3 million rows, and the city demographics data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_imm =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "#df_imm =spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(cicid=6.0, i94yr=2016.0, i94mon=4.0, i94cit=692.0, i94res=692.0, i94port='XXX', arrdate=20573.0, i94mode=None, i94addr=None, depdate=None, i94bir=37.0, i94visa=2.0, count=1.0, dtadfile=None, visapost=None, occup=None, entdepa='T', entdepd=None, entdepu='U', matflag=None, biryear=1979.0, dtaddto='10282016', gender=None, insnum=None, airline=None, admnum=1897628485.0, fltno=None, visatype='B2'),\n",
       " Row(cicid=7.0, i94yr=2016.0, i94mon=4.0, i94cit=254.0, i94res=276.0, i94port='ATL', arrdate=20551.0, i94mode=1.0, i94addr='AL', depdate=None, i94bir=25.0, i94visa=3.0, count=1.0, dtadfile='20130811', visapost='SEO', occup=None, entdepa='G', entdepd=None, entdepu='Y', matflag=None, biryear=1991.0, dtaddto='D/S', gender='M', insnum=None, airline=None, admnum=3736796330.0, fltno='00296', visatype='F1'),\n",
       " Row(cicid=15.0, i94yr=2016.0, i94mon=4.0, i94cit=101.0, i94res=101.0, i94port='WAS', arrdate=20545.0, i94mode=1.0, i94addr='MI', depdate=20691.0, i94bir=55.0, i94visa=2.0, count=1.0, dtadfile='20160401', visapost=None, occup=None, entdepa='T', entdepd='O', entdepu=None, matflag='M', biryear=1961.0, dtaddto='09302016', gender='M', insnum=None, airline='OS', admnum=666643185.0, fltno='93', visatype='B2'),\n",
       " Row(cicid=16.0, i94yr=2016.0, i94mon=4.0, i94cit=101.0, i94res=101.0, i94port='NYC', arrdate=20545.0, i94mode=1.0, i94addr='MA', depdate=20567.0, i94bir=28.0, i94visa=2.0, count=1.0, dtadfile='20160401', visapost=None, occup=None, entdepa='O', entdepd='O', entdepu=None, matflag='M', biryear=1988.0, dtaddto='09302016', gender=None, insnum=None, airline='AA', admnum=92468461330.0, fltno='00199', visatype='B2'),\n",
       " Row(cicid=17.0, i94yr=2016.0, i94mon=4.0, i94cit=101.0, i94res=101.0, i94port='NYC', arrdate=20545.0, i94mode=1.0, i94addr='MA', depdate=20567.0, i94bir=4.0, i94visa=2.0, count=1.0, dtadfile='20160401', visapost=None, occup=None, entdepa='O', entdepd='O', entdepu=None, matflag='M', biryear=2012.0, dtaddto='09302016', gender=None, insnum=None, airline='AA', admnum=92468463130.0, fltno='00199', visatype='B2')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_imm.count())\n",
    "df_imm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"us-cities-demographics.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(City='Silver Spring', State='Maryland', Median Age='33.8', Male Population='40601', Female Population='41862', Total Population='82463', Number of Veterans='1562', Foreign-born='30908', Average Household Size='2.6', State Code='MD', Race='Hispanic or Latino', Count='25924'),\n",
       " Row(City='Quincy', State='Massachusetts', Median Age='41.0', Male Population='44129', Female Population='49500', Total Population='93629', Number of Veterans='4147', Foreign-born='32935', Average Household Size='2.39', State Code='MA', Race='White', Count='58723'),\n",
       " Row(City='Hoover', State='Alabama', Median Age='38.5', Male Population='38040', Female Population='46799', Total Population='84839', Number of Veterans='4819', Foreign-born='8229', Average Household Size='2.58', State Code='AL', Race='Asian', Count='4759'),\n",
       " Row(City='Rancho Cucamonga', State='California', Median Age='34.5', Male Population='88127', Female Population='87105', Total Population='175232', Number of Veterans='5821', Foreign-born='33878', Average Household Size='3.18', State Code='CA', Race='Black or African-American', Count='24437'),\n",
       " Row(City='Newark', State='New Jersey', Median Age='34.6', Male Population='138040', Female Population='143873', Total Population='281913', Number of Veterans='5829', Foreign-born='86253', Average Household Size='2.73', State Code='NJ', Race='White', Count='76402')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_cities.count())\n",
    "df_cities.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Immigration Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df  = df_imm.select(['i94cit', 'i94port', 'arrdate', 'i94mode', 'i94bir', 'i94visa', 'count'])\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+------+-------+-----+\n",
      "|i94cit|i94port|arrdate|i94mode|i94bir|i94visa|count|\n",
      "+------+-------+-------+-------+------+-------+-----+\n",
      "|     0|      0|      0|    239|   802|      0|    0|\n",
      "+------+-------+-------+-------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the immigration dataframe\n",
    "\n",
    "df.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the columns relevant to our analysis :\n",
    "\n",
    "\n",
    "- i94cit : According to the data dictionary, this column has invalid codes like 'INVALID: INTERNATIONAL WATERS' and 'No Country Code (100)'. \n",
    "- i94port : This column has invalid codes like 'XXX : NOT REPORTED/UNKNOWN' or , 'GAC : 'No PORT Code (GAC)'\n",
    "- arrdate : We can see from the schema printed above that this variable is in a numeric format and will have to be converted. \n",
    "- i94mode : There are missing values as well as 'Not reported'.\n",
    "- i94bir : There are missing values here\n",
    "- i94visa : No missing values\n",
    "- count : No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**City Demographics Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cit = df_cities.select(['City', 'State Code', 'Median Age', 'Male Population', 'Female Population', 'Total Population', 'Foreign-born', 'Race'])\n",
    "df_cit.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+---------------+-----------------+----------------+------------+----+\n",
      "|City|State Code|Median Age|Male Population|Female Population|Total Population|Foreign-born|Race|\n",
      "+----+----------+----------+---------------+-----------------+----------------+------------+----+\n",
      "|   0|         0|         0|              3|                3|               0|          13|   0|\n",
      "+----+----------+----------+---------------+-----------------+----------------+------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the immigration dataframe\n",
    "\n",
    "df_cit.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df_cit.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the columns relevant to our analysis :\n",
    "\n",
    "- City : No missing values\n",
    "- State Code : No missing values\n",
    "- Median Age : No missing values\n",
    "- Male Population : Missing values, variable is string\n",
    "- Female Population : Missing values, variable is string\n",
    "- Total Population : No missing values, variable is string\n",
    "- Foreign-born : Missing values, variable is string\n",
    "- Race : No missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data\n",
    "\n",
    "**Immigration Dataset**\n",
    "\n",
    "- i94cit : We will remove all invalid codes as a first step towards creating a country dimension \n",
    "- i94port : We will remove all invalid codes as a first step towards creating a city dimension \n",
    "- arrdate : We will convert this to timestamp format prior to creating a time dimension\n",
    "- i94mode : We will club missing values and 'not reported' together\n",
    "- i94bir : We will impute missing values with the average for the dataset\n",
    "\n",
    "\n",
    "**City Demographics Dataset**\n",
    "- We will group the data by city and state code\n",
    "- We will add a new column mapped to 'i94port' in the immigration table as a step towards making this a dimension table\n",
    "- Median Age, Total Population : We will convert to numeric and aggregate\n",
    "- Male Population, Female population, Foreign-born : We will convert to numeric, impute missing values with mean value and aggregate \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Immigration Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary of valid i94cit codes\n",
    "patt = re.compile(r\"^\\s*(?P<code>\\d+)\\s*=\\s*'(?P<country>.+)'.*$\")\n",
    "with open('valid_country_code.txt') as f:\n",
    "    country_lines = f.readlines()\n",
    "    \n",
    "matches = [patt.match(line) for line in country_lines]\n",
    "country_codes_valid = {int(match.group('code')): match.group('country') for match in matches}\n",
    "assert len(country_lines) == len(country_codes_valid)\n",
    "#country_codes_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove invalid i94cit codes\n",
    "df = df.filter(df.i94cit.isin(list(country_codes_valid.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary of valid i94port codes\n",
    "patt = re.compile(r\"^\\s*'(?P<code>...?)'\\s*=\\s*'(?P<name>.+)'.*$\")\n",
    "with open('valid_port_code.txt') as f:\n",
    "    port_lines = f.readlines()\n",
    "matches = [patt.match(line) for line in port_lines]\n",
    "port_codes_valid = {match.group('code'): match.group('name').strip() for match in matches}\n",
    "assert len(port_codes_valid) == len(port_lines)\n",
    "#port_codes_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split city and state\n",
    "for key, value in port_codes_valid.items():\n",
    "    port_codes_valid[key] = value.split(\",\")\n",
    "#port_codes_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove invalid i94port codes\n",
    "df = df.filter(df.i94port.isin(list(port_codes_valid.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2587323"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create date column from arrdate\n",
    "import datetime\n",
    "\n",
    "get_ts = F.udf(lambda x: (datetime.timedelta(days=x) + datetime.datetime(1960,1,1)).strftime('%Y-%m-%d')) \n",
    "df = df.withColumn('arrival_date', F.to_date(get_ts(df.arrdate)))\n",
    "\n",
    "# create year, month, day, day of week columns from timestamp column\n",
    "df = df.withColumn(\"arr_year\", F.year(F.col('arrival_date')))\\\n",
    "                .withColumn(\"arr_month\", F.month(F.col(\"arrival_date\")))\\\n",
    "                .withColumn(\"arr_day\", F.dayofmonth(F.col(\"arrival_date\")))\\\n",
    "                .withColumn(\"arr_day_of_week\", F.dayofweek(F.col(\"arrival_date\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code null values in the i94mode column as 9 ('not reported')\n",
    "\n",
    "df = df.na.fill(9.0, subset = ['i94mode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute missing values in i94bir with mean\n",
    "\n",
    "mean_val = df.select(F.mean(df['i94bir'])).collect()\n",
    "mean_age = mean_val[0][0]\n",
    "df = df.na.fill(mean_age, ['i94bir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+------+-------+------------+--------+---------+-------+---------------+-----+\n",
      "|i94cit|i94port|i94mode|i94bir|i94visa|arrival_date|arr_year|arr_month|arr_day|arr_day_of_week|count|\n",
      "+------+-------+-------+------+-------+------------+--------+---------+-------+---------------+-----+\n",
      "| 101.0|    WAS|    1.0|  55.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  28.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|   4.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  57.0|    1.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  63.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  57.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  46.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  48.0|    1.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  52.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    BOS|    1.0|  58.0|    1.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    ATL|    1.0|  56.0|    1.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    ATL|    1.0|  62.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    ATL|    1.0|  49.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    ATL|    1.0|  43.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    HOU|    1.0|  53.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  48.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  74.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  37.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  49.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "| 101.0|    NYC|    1.0|  33.0|    2.0|  2016-04-01|    2016|        4|      1|              6|  1.0|\n",
      "+------+-------+-------+------+-------+------------+--------+---------+-------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final = df.select(['i94cit', 'i94port', 'i94mode', 'i94bir', 'i94visa', 'arrival_date', 'arr_year', 'arr_month', 'arr_day', 'arr_day_of_week', 'count'])\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+------+-------+------------+--------+---------+-------+---------------+-----+\n",
      "|i94cit|i94port|i94mode|i94bir|i94visa|arrival_date|arr_year|arr_month|arr_day|arr_day_of_week|count|\n",
      "+------+-------+-------+------+-------+------------+--------+---------+-------+---------------+-----+\n",
      "|     0|      0|      0|     0|      0|           0|       0|        0|      0|              0|    0|\n",
      "+------+-------+-------+------+-------+------------+--------+---------+-------+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check there are no more missing values\n",
    "df_final.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_final.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- i94mode: double (nullable = false)\n",
      " |-- i94bir: double (nullable = false)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- arr_year: integer (nullable = true)\n",
      " |-- arr_month: integer (nullable = true)\n",
      " |-- arr_day: integer (nullable = true)\n",
      " |-- arr_day_of_week: integer (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**City Demographics Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert relevant columns to numeric\n",
    "from pyspark.sql.types import IntegerType\n",
    "df_cit = df_cit.withColumn('MedianAge', df_cit['Median Age'].cast(IntegerType())).drop('Median Age')\n",
    "df_cit = df_cit.withColumn('Male_Population', df_cit['Male Population'].cast(IntegerType())).drop('Male Population')\n",
    "df_cit = df_cit.withColumn('Female_Population', df_cit['Female Population'].cast(IntegerType())).drop('Female Population')\n",
    "df_cit = df_cit.withColumn('Total_Population', df_cit['Total Population'].cast(IntegerType())).drop('Total Population')\n",
    "df_cit = df_cit.withColumn('Foreign_Born', df_cit['Foreign-born'].cast(IntegerType())).drop('Foreign-born')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute missing values with mean\n",
    "#Male Population\n",
    "mean_val = df_cit.select(F.mean(df_cit['Male_Population'])).collect()\n",
    "mean_male_pop = mean_val[0][0]\n",
    "df_cit = df_cit.na.fill(mean_male_pop, ['Male_Population'])\n",
    "#Female Population\n",
    "mean_val = df_cit.select(F.mean(df_cit['Female_Population'])).collect()\n",
    "mean_female_pop = mean_val[0][0]\n",
    "df_cit = df_cit.na.fill(mean_female_pop, ['Female_Population'])\n",
    "#Foreign Born\n",
    "mean_val = df_cit.select(F.mean(df_cit['Foreign_Born'])).collect()\n",
    "mean_foreign_born = mean_val[0][0]\n",
    "df_cit = df_cit.na.fill(mean_foreign_born, ['Foreign_Born'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to aggregate 'MedianAge' and 'Race' by most frequent value when grouping by city and state code\n",
    "import pyspark.sql.functions as F\n",
    "@F.udf\n",
    "def mode(x):    \n",
    "    '''\n",
    "    This function returns the most frequent value\n",
    "    '''\n",
    "    from collections import Counter\n",
    "    return Counter(x).most_common(1)[0][0]\n",
    "\n",
    "cols = ['MedianAge', 'Race']\n",
    "agg_expr = [mode(F.collect_list(col)).alias(col) for col in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset grouped by city and state code\n",
    "grouped = df_cit.groupBy(F.col('City'), F.col('State Code'))\n",
    "df_cit_grouped_1 = grouped.agg({'Male_Population' : 'sum', 'Female_Population' : 'sum', 'Total_Population' : 'sum','Foreign_Born' : 'sum'})\n",
    "df_cit_grouped_2 = grouped.agg(*agg_expr)\n",
    "\n",
    "df_cit_final = df_cit_grouped_1.join(df_cit_grouped_2, ['City', 'State Code'])\n",
    "df_cit_final = df_cit_final.withColumnRenamed('State Code', 'State_Code')\n",
    "df_cit_final = df_cit_final.withColumnRenamed('sum(Total_Population)', 'Total_Population')\n",
    "df_cit_final = df_cit_final.withColumnRenamed('sum(Male_Population)', 'Male_Population')\n",
    "df_cit_final = df_cit_final.withColumnRenamed('sum(Female_Population)', 'Female_Population')\n",
    "df_cit_final = df_cit_final.withColumnRenamed('sum(Foreign_Born)', 'Foreign_born')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cit_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add i94 port code to the city dataset\n",
    "\n",
    "\n",
    "@F.udf()\n",
    "def get_i94port(city, state_code):\n",
    "    '''\n",
    "    Input: City name, State code\n",
    "    \n",
    "    Output: Corresponding i94port\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for key in port_codes_valid:\n",
    "        if (city.lower() in port_codes_valid[key][0].lower()) & (state_code in port_codes_valid[key][1]):\n",
    "            return key\n",
    "        \n",
    "# Add i94port code based on city name\n",
    "df_cities_final =df_cit_final.withColumn(\"i94port\", get_i94port(df_cit_final.City, df_cit_final.State_Code))\n",
    "# Remove entries with no iport94 code\n",
    "df_cities_final =df_cities_final.filter(df_cities_final.i94port != 'null')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|i94port|count|\n",
      "+-------+-----+\n",
      "|    CID|    2|\n",
      "|    MCA|    2|\n",
      "|    RDU|    2|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check if i94port column is a unique key\n",
    "df_cities_final.groupBy('i94port').count().filter('count > 1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are duplicates for 3 i94port values above. Let us examine them in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------------+-----------------+---------------+------------+---------+--------------------+-------+\n",
      "|        City|State_Code|Total_Population|Female_Population|Male_Population|Foreign_born|MedianAge|                Race|i94port|\n",
      "+------------+----------+----------------+-----------------+---------------+------------+---------+--------------------+-------+\n",
      "|   Iowa City|        IA|          371135|           185690|         185445|       46010|       25|Black or African-...|    CID|\n",
      "|Cedar Rapids|        IA|          652025|           336480|         315545|       27020|       36|               White|    CID|\n",
      "+------------+----------+----------------+-----------------+---------------+------------+---------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cities_final.filter(df_cities_final['i94port'] == 'CID').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue here is that data dictionary shows the value for key 'CID' as 'Cedar Rapids/Iowa City. To avoid the conflict we will keep the row for the bigger city (in terms of total population) 'Cedar Rapids' and drop the other row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------------+-----------------+---------------+------------+---------+--------------------+-------+\n",
      "|   City|State_Code|Total_Population|Female_Population|Male_Population|Foreign_born|MedianAge|                Race|i94port|\n",
      "+-------+----------+----------------+-----------------+---------------+------------+---------+--------------------+-------+\n",
      "| Durham|        NC|         1287990|           682225|         605765|      193210|       33|               White|    RDU|\n",
      "|Raleigh|        NC|         2259745|          1163825|        1095920|      325625|       32|Black or African-...|    RDU|\n",
      "+-------+----------+----------------+-----------------+---------------+------------+---------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cities_final.filter(df_cities_final['i94port'] == 'RDU').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same problem as above. We will keep the record for the bigger city Raleigh and remove the record for Durham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------------+-----------------+---------------+------------+---------+--------------------+-------+\n",
      "|   City|State_Code|Total_Population|Female_Population|Male_Population|Foreign_born|MedianAge|                Race|i94port|\n",
      "+-------+----------+----------------+-----------------+---------------+------------+---------+--------------------+-------+\n",
      "|  Allen|        TX|          490690|           234070|         256620|       98245|       37|American Indian a...|    MCA|\n",
      "|McAllen|        TX|          701265|           359605|         341660|      188455|       32|Black or African-...|    MCA|\n",
      "+-------+----------+----------------+-----------------+---------------+------------+---------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cities_final.filter(df_cities_final['i94port'] == 'MCA').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conflict here arises because 'Allen' is part of the string 'McAllen'. We will drop the record for Allen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities_final = df_cities_final.filter(df_cities_final['City'] != 'Iowa City')\n",
    "df_cities_final = df_cities_final.filter(df_cities_final['City'] != 'Durham')\n",
    "df_cities_final = df_cities_final.filter(df_cities_final['City'] != 'Allen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- Total_Population: long (nullable = true)\n",
      " |-- Female_Population: long (nullable = true)\n",
      " |-- Male_Population: long (nullable = true)\n",
      " |-- Foreign_born: long (nullable = true)\n",
      " |-- MedianAge: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_cities_final.count())\n",
    "df_cities_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities_final = df_cities_final.withColumn('Median_Age', df_cities_final['MedianAge'].cast(IntegerType())).drop('MedianAge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "The objective of the exercise is to find out which countries immigrants are coming from, their mode of travel ,type of visa and which cities in the U.S. they are arriving to, in order to see if demographics of cities influence immigration patterns. Accordingly the following dimension tables and fact table (arranged in a star schema) were created to facilitate the analysis.\n",
    "\n",
    "- **Dimension Table City_of_Arrival**\n",
    "\n",
    "- **Dimension Table Country_of_Origin**\n",
    "\n",
    "- **Dimension Table Mode_of_Travel**\n",
    "\n",
    "- **Dimension Table Type_of_Visa**\n",
    "\n",
    "- **Dimension Table Time**\n",
    "\n",
    "- **Fact Table Immigration_Fact**\n",
    "\n",
    "The details of the fields in each table and source of data are provided in the Data Dictionary below\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Clean I94 data as described in the 'Cleaning Steps' section to create spark dataframe df_final\n",
    "2. Clean city demograhics data as described in the 'Cleaning Steps' section to create spark dataframe df_cities_final\n",
    "3. Create city_of_arrival dimension table from the df_cities_final dataframe and write to parquet file partitioned by i94port\n",
    "4. Create country_of_origin dimension table from the country_codes_valid dictionary and write to parquet file partitioned by i94cit\n",
    "5. Create mode_of_travel dimension table from data dictionary and write to parquet file\n",
    "6. Create type_of_visa dimension table from data dictionary and write to parquet file\n",
    "7. Create time dimension table from df_final and write to parquet file partitioned by year and month\n",
    "8. Create immigration_fact table from df_final and write to parquet file partitioned by i94 cit and i94port\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create city_of_arrival dimension table\n",
    "city_of_arrival = df_cities_final.select(['i94port', 'City', 'State_Code', 'Male_Population', 'Female_Population', 'Total_Population', \\\n",
    "                                          'Foreign_born', 'Median_Age', 'Race']) \n",
    "\n",
    "city_of_arrival.write.partitionBy('i94port').parquet('tables/city_of_arrival', \"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create country of origin dimension table\n",
    "#Convert dictionary to pandas dataframe\n",
    "country_codes_df = pd.DataFrame.from_dict(country_codes_valid, orient = 'index', columns = ['Country_Name'])\n",
    "country_codes_df.reset_index(level = 0, inplace = True)\n",
    "country_codes_df = country_codes_df.rename(columns = {\"index\" : \"i94cit\"})\n",
    "#Create spark dataframe\n",
    "country_of_origin = spark.createDataFrame(country_codes_df)\n",
    "#Write to parquet\n",
    "country_of_origin.write.partitionBy('i94cit').parquet('tables/country_of_origin', \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create mode of travel dimension table\n",
    "mode_dict = {1.0 : 'Air', 2.0 : 'Sea', 3.0 : 'Land', 9.0 : 'Not reported' }\n",
    "mode_df = pd.DataFrame.from_dict(mode_dict, orient = 'index', columns = ['Mode_of_Arrival'])\n",
    "mode_df.reset_index(level = 0, inplace = True)\n",
    "mode_df = mode_df.rename(columns = {'index' : 'i94mode'})\n",
    "\n",
    "#Create spark dataframe\n",
    "mode_of_travel = spark.createDataFrame(mode_df)\n",
    "#Write to parquet\n",
    "mode_of_travel.write.parquet('tables/mode_of_travel ', \"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create type of visa dimension table\n",
    "visa_dict = {1 : 'Business', 2 : 'Pleasure', 3 : 'Student'}\n",
    "visa_df = pd.DataFrame.from_dict(visa_dict, orient = 'index', columns = ['Visa_Type'])\n",
    "visa_df.reset_index(level = 0, inplace = True)\n",
    "visa_df = visa_df.rename(columns = {'index' : 'i94visa'})\n",
    "\n",
    "#Create spark dataframe\n",
    "type_of_visa = spark.createDataFrame(visa_df)\n",
    "#Write to parquet\n",
    "type_of_visa.write.parquet('tables/type_of_visa ', \"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create time dimension table\n",
    "time_table = df_final.select(F.col('arrival_date').alias('date'), F.col('arr_year').alias('year'), F.col('arr_month').alias('month'), F.col('arr_day').alias('day'), F.col('arr_day_of_week').alias('dayofweek')).dropDuplicates([\"date\"])\n",
    "# write time table to parquet files partitioned by year and month\n",
    "time_table.write.partitionBy(\"year\", \"month\").parquet(\"tables/time\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create immigration fact table\n",
    "\n",
    "immigration_fact = df_final.select(['i94cit', 'i94port', 'i94mode', 'i94bir', 'i94visa', 'arrival_date', 'count'])\\\n",
    "                .withColumn(\"immigration_id\", F.monotonically_increasing_id())\n",
    "immigration_fact.write.partitionBy('i94cit', 'i94port').parquet('tables/immigration_fact', 'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quality Check 1: Ensure there are adequate entries in each table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data count check passed for immigration fact table with 2587323 records\n",
      "Data count check passed for time table with 30 records\n",
      "Data count check passed for type of visa table with 3 records\n",
      "Data count check passed for mode of travel table with 4 records\n",
      "Data count check passed for country of origin table with 236 records\n",
      "Data count check passed for city of arrival table with 135 records\n"
     ]
    }
   ],
   "source": [
    "# Perform quality check 1 here\n",
    "def quality_check_count(df, description):\n",
    "    '''\n",
    "    Input: Spark dataframe, description of Spark datafram\n",
    "    \n",
    "    Output: Print outcome of data quality check\n",
    "    '''\n",
    "    \n",
    "    result = df.count()\n",
    "    if result == 0:\n",
    "        print(\"Data count check failed for {} with zero records\".format(description))\n",
    "    else:\n",
    "        print(\"Data count check passed for {} with {} records\".format(description, result))\n",
    "        \n",
    "quality_check_count(immigration_fact, \"immigration fact table\")\n",
    "quality_check_count(time_table, \"time table\")\n",
    "quality_check_count(type_of_visa, \"type of visa table\")\n",
    "quality_check_count(mode_of_travel, \"mode of travel table\")\n",
    "quality_check_count(country_of_origin, \"country of origin table\")\n",
    "quality_check_count(city_of_arrival, \"city of arrival table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quality Check 2: Ensure that primary keys have unique values in each table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique key constraint check passed for column immigration_id in immigration fact table\n",
      "Unique key constraint check passed for column date in time table\n",
      "Unique key constraint check passed for column i94visa in type of visa table\n",
      "Unique key constraint check passed for column i94mode in mode of travel table\n",
      "Unique key constraint check passed for column i94cit in country of origin table\n",
      "Unique key constraint check passed for column i94port in city of arrival table\n"
     ]
    }
   ],
   "source": [
    "def quality_check_unique_key(df, column, description):\n",
    "    '''\n",
    "    Input: Spark dataframe, column name, description\n",
    "    Output: Print outcome of data quality check\n",
    "    '''\n",
    "    if df.select(column).distinct().count() == df.count():\n",
    "        print(\"Unique key constraint check passed for column {} in {}\".format(column, description))\n",
    "    else:\n",
    "        print(\"Unique key constraint check failed for column {} in {}\".format(column, description))\n",
    "        \n",
    "quality_check_unique_key(immigration_fact, 'immigration_id', \"immigration fact table\")\n",
    "quality_check_unique_key (time_table, 'date', \"time table\")\n",
    "quality_check_unique_key(type_of_visa, 'i94visa', \"type of visa table\")\n",
    "quality_check_unique_key(mode_of_travel, 'i94mode', \"mode of travel table\")\n",
    "quality_check_unique_key(country_of_origin, 'i94cit', \"country of origin table\")\n",
    "quality_check_unique_key(city_of_arrival, 'i94port', \"city of arrival table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "**Dimension Table City_of_Arrival**\n",
    "\n",
    "This is essentially the df_cities_final dataframe created above with the following columns:\n",
    "- i94port : 3 character code, string, primary key\n",
    "- City : Name of city, string\n",
    "- State_Code : 2 character state code, string\n",
    "- Male_population : population, numeric\n",
    "- Female_population : population, numeric\n",
    "- Total_population : population, numeric \n",
    "- Foreign-born : population, numeric \n",
    "- Median Age : median age, numeric\n",
    "- Race : race, string\n",
    "\n",
    "**Dimension Table Country_of_Origin**\n",
    "\n",
    "This is created from the 'country_codes_valid' dictionary created above with the following columns:\n",
    "- i94cit : 3 character country code, string, primary key\n",
    "- country_name : Name of country, string\n",
    "\n",
    "**Dimension Table Mode_of_Travel**\n",
    "\n",
    "This is created from a dictionary of i94mode values in the data dictionary with the following columns:\n",
    "- i94mode : code, numeric, primary key\n",
    "- travel_mode : mode of travel, string\n",
    "\n",
    "**Dimension Table Type_of_Visa**\n",
    "\n",
    "This is created from a dictionary of i94visa values in the data dictionary with the following columns:\n",
    "- i94visa : code, numeric, primary key\n",
    "- visa_type : type of visa, string\n",
    "\n",
    "**Dimension Table Time**\n",
    "\n",
    "This is created from the df_imm_final dataframe with the following columns:\n",
    "\n",
    "- date : date, primary key\n",
    "- year : year, numeric\n",
    "- month : month, numeric\n",
    "- day : day, numeric\n",
    "- dayofweek : day of week, numeric\n",
    "\n",
    "**Fact Table Immigration_Fact**\n",
    "\n",
    "This is created from the df_imm_final dataframe with the following columns:\n",
    "- immigration_id : numeric, primary key\n",
    "- i94cit string, foreign key\n",
    "- i94port string, foreign key\n",
    "- i94mode numeric, foreign key\n",
    "- i94bir numeric\n",
    "- i94visa numeric, foreign key\n",
    "- arrival_date date, foreign key\n",
    "- count numeric\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "Spark was chosen since it can easily handle multiple file formats (including SAS) containing large amounts of data. Spark SQL was chosen to process the large input files into dataframes and manipulate them via standard select and create dataframe operations to form additional tables.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "\n",
    "1. The immigration_fact table should be updated on a monthly basis when each new dataset is available\n",
    "2. With a data dictionary as provided here, all dimension tables sourced from the immigration data can be recreated \n",
    "3. The city_of_arrival dimension table currently does not have a time component. If new data is available in the future the table should be updated at that time. \n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " \n",
    "If the data was increased by 100x we could consider moving Spark to cluster mode using a cluster manager such as Yarn.\n",
    " \n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " \n",
    "\n",
    "If the data needs to populate a dashboard that updates daily by 7 am, then we could use a scheduling tool such as Airflow to run the ETL pipeline overnight.\n",
    " \n",
    " * The database needed to be accessed by 100+ people.\n",
    " \n",
    " \n",
    " If the database needs to be accessed by 100+ people we could have the data replicate to different nodes used by different users. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
